{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4fb902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "limit = 80\n",
    "file = open(\"C:/Users/V-5.0/Documents/Python_Jupiter/project/SpeedRecord.txt\",\"w\")\n",
    "file.write(\"ID\\t SPEED\\n ------\\t---------\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c120f4f",
   "metadata": {},
   "source": [
    "## Speed Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77e309ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EuclideanDistTracker:\n",
    "    def __init__(self):\n",
    "        # Store the center positions of the objects\n",
    "        self.center_points = {}\n",
    "        self.id_count = 0\n",
    "        #self.start = 0\n",
    "        #self.stop = 0\n",
    "        self.et = 0\n",
    "        self.s1 = np.zeros((1,1000))\n",
    "        self.s2 = np.zeros((1,1000))\n",
    "        self.s = np.zeros((1,1000))\n",
    "        self.f = np.zeros(1000)\n",
    "        self.capf = np.zeros(1000)\n",
    "        self.count = 0\n",
    "        self.exceeded = 0\n",
    "    def update(self, objects_rect):\n",
    "        objects_bbs_ids = []\n",
    "        \n",
    "        # Get center point of new object\n",
    "        for rect in objects_rect:\n",
    "            x,y,w,h = rect\n",
    "            cx = (x+x+w)//2\n",
    "            cy = (y+y+h)//2\n",
    "            \n",
    "            # Check if object is detected already\n",
    "            same_object_detected = False\n",
    "            for id, pt in self.center_points.items():\n",
    "                dist = math.hypot(cx-pt[0], cy-pt[1])\n",
    "                \n",
    "                if dist < 70:\n",
    "                    self.center_points[id] = (cx,cy)\n",
    "                    objects_bbs_ids.append([x,y,w,h])\n",
    "                    same_object_detected = True\n",
    "                    # Stop timer\n",
    "                    if (y>= 410 and y<=430):\n",
    "                        self.s1[0,id] = time.time()\n",
    "                        print(\"starting time id\",id,self.s1[0,id],id)\n",
    "                    \n",
    "                    # Start timer and Find difference\n",
    "                    if(y>=235 and y<255):\n",
    "                        self.s2[0,id] = time.time()\n",
    "                        print(\"stop time id\",id,self.s2[0,id],id)\n",
    "                        self.s[0,id] = time.time()\n",
    "                        print(\"difference id\",id,self.s[0,id],id)\n",
    "                    \n",
    "                    # Capture Flag\n",
    "                    if(y<430):\n",
    "                        self.f[id] = 1\n",
    "            print('detected ? ',same_object_detected)\n",
    "            \n",
    "            # New object Detection\n",
    "            if same_object_detection is False:\n",
    "                self.center_points[self.id_count] = (cx,cy)\n",
    "                objects_bbs_ids.append([x,y,w,h, self.id_count])\n",
    "                self.id_count+=1\n",
    "                self.s[0,self.id_count] = 0\n",
    "                self.s1[0,self.id_count] = 0\n",
    "                self.s2[0,self.id_count] = 0\n",
    "            \n",
    "            # Assign New ID to object\n",
    "            new_center_points = {}\n",
    "            for obj_bb_id in objects_bbs_ids:\n",
    "                _,_,_,_, object_id = obj_bb_id\n",
    "                center = self.center_points[object_id]\n",
    "                new_center_points[object_id] = center\n",
    "            \n",
    "            self.center_points = new_center_points.copy()\n",
    "            return objects_bbs_ids\n",
    "    # Speed Function\n",
    "    def getsp(self,id):\n",
    "        if(self.s[0,id]!=0):\n",
    "            s = 214.15/self.s[0,id]\n",
    "        else:\n",
    "            s=0\n",
    "        return int(s)\n",
    "    # Save vehicle data\n",
    "    def capture(self,img,x,y,h,w,sp,id):\n",
    "        if(self.capf[id]==0):\n",
    "            self.capf[id] = 1\n",
    "            self.f[id] = 0\n",
    "            crop_img= img[y-5:y+h+5, x-5:x+w+5]\n",
    "            n = str(id)+\"speed_\"+str(sp)\n",
    "            file='D://Record//'+n+\".jpg\"\n",
    "            cv2.imwrite(file, crop_img)\n",
    "            self.count += 1\n",
    "            filet = open(\"C:/Users/V-5.0/Documents/Python_Jupiter/project/SpeedRecord.txt\",\"a\")\n",
    "            if(sp>limit):\n",
    "                file2 = \"C:/Users/V-5.0/Documents/Python_Jupiter/project/exceeded/\"+n+'.jpg'\n",
    "                cv2.imwrite(file2, crop_img)\n",
    "                filet.write(str(id)+'\\t'+str(sp)+\"<======exceeded\\n\")\n",
    "                self.exceeded+=1\n",
    "            else:\n",
    "                filet.write(str(id)+\"\\t\"+str(sp)+\"\\n\")\n",
    "            filet.close()\n",
    "            \n",
    "    #Speed limit\n",
    "    def limit(self):\n",
    "        return limit\n",
    "    \n",
    "    # text file summary\n",
    "    def end(self):\n",
    "        file = open(\"C:/Users/V-5.0/Documents/Python_Jupiter/project/SpeedRecord.txt\",\"a\")\n",
    "        file.write(\"\\n-------------\\n\")\n",
    "        file.write(\"----------------\\n\")\n",
    "        file.write(\"Summary\\n\")\n",
    "        file.write(\"----------------\\n\")\n",
    "        file.write(\"Total Vehicles:\\t\"+str(self.count)+\"\\n\")\n",
    "        file.write(\"Exceeded speed limit:\\t\"+str(self.exceeded))\n",
    "        file.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8820a873",
   "metadata": {},
   "source": [
    "## Speed detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbbf616",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required Libraries\n",
    "import cv2\n",
    "# it is a python file consist methods to calculate speed and update the cordinates\n",
    "from tracker2 import\n",
    "import numpy as np\n",
    "end = 0\n",
    "#Creater Tracker Object that was imported from tracker2 python file tracker EuclideanDistTracker() 2\n",
    "#Read the video file\n",
    "cap = cv2.VideoCapture(\"traffic4.mp4\")\n",
    "#its flag value to identify same object or not\n",
    "f = 25\n",
    "w = int(1000/(f-1))\n",
    "#create a object for Object Detection using background subtraction method\n",
    "object_detector = cv2.createBackgroundSubtractor 062(history-100, var Threshold=5)\n",
    "#KERNALS\n",
    "kernalOp = np.ones((3,3), np.uint8)\n",
    "kerna1Op2 = np.ones((5,5), np.uint8)\n",
    "kernalC1= np.ones((11,11), np.uint8)\n",
    "fghg=cv2.createBackgroundSubtractorMOG2(detectShadows=True) \n",
    "kernal_e = np.ones((5,5), np.uint8)\n",
    "while True:\n",
    "    #read the frames of video\n",
    "    ret, frame cap.read()\n",
    "    #resize the video frames\n",
    "    frame = cv2.resize(frame, None, fx=0.5, fy=0.5)\n",
    "    #geth the height and width of video file\n",
    "    height, width,_= frame.shape\n",
    "    #Create Region of Interest extract it from video\n",
    "    roi=frame[50:540,200:960]\n",
    "    \n",
    "    #MASKING METHOD 1\n",
    "    mask= object_detector.apply(roi) \n",
    "    _,mask= cv2.threshold(mask, 250, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    #DIFFERENT MASKING METHOD 2 This is used\n",
    "    fgmask= fgbg.apply(roi)\n",
    "    ret, inBin cv2.threshold (fgmask, 200, 255, cv2.THRESH_BINARY)\n",
    "    mask1= cv2.morphologyEx(imBin, cv2.MORPH_OPEN, kernalOp) \n",
    "    mask2= cv2.morphologyEx(mask1, cv2.MORPH_CLOSE, kernaICl)\n",
    "    #erode the masked image\n",
    "    e_img= cv2.erode(mask2, kernal_e)\n",
    "    #contours are used to detect small areas in whole image\n",
    "    #Use this if below Line doesn't work(contours, cv2.findContours (eing,cv2.RETR_TREE,cv2.CHAIN APPROX SIMPLE)) \n",
    "    contours = cv2.findContours (e_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[1]\n",
    "    \n",
    "    #create empty list of detected objects\n",
    "    detections = []\n",
    "    #Loop through all the identified objects in contours\n",
    "    for cnt in contours:\n",
    "        #calculate the area of nested objects\n",
    "        area= cv2.contourArea(cnt) #decide threshold to consider and then draw a boundary to that objects\n",
    "        if area >1000:\n",
    "            #create rectangle aroung contour \n",
    "            x,y,w,h= cv2.boundingRect(cnt)\n",
    "            #show that rectange in region of interest (.e draw that circle until it crosses rai\n",
    "            cv2.rectangle(roi, (x,y), (x+w, y+h), (0,255,0),3) \n",
    "            #now append the valus to detections List\n",
    "            detections.append([x,y,w,h])\n",
    "    #track the objects and update coordinates by using update method tracker object of tracker class\n",
    "    boxes ids tracker.update(detections)\n",
    "    #Loop through the box id \n",
    "    for box_id in boxes_ids:\n",
    "    #get coordinates of current bar id\n",
    "        x,y,w,h=box_id\n",
    "        #track speed of tracker and then check whether it has crossed speed limit\n",
    "        if(tracker.getsp(id) <tracker.limit()):\n",
    "            #if doesnot crossed then display the id and speed of vehicle and display border in green color \n",
    "            cv2.putText(roi, str(id)+\" \"+str(tracker.getsp(id)), (x,y-15), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255,0),2) \n",
    "            cv2.rectangle(roi, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "        else:\n",
    "            #else then display the id and speed of vehicle and display the border in red color \n",
    "            cv2.putText(roi, str(id)+\" \"+str(tracker.getsp(id)), (x, y-15), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 2) \n",
    "            cv2.rectangle(roi, (x, y), (x+w, y + h), (0, 165, 255), 3)\n",
    "        #get speed and check whether\n",
    "        s = tracker.getsp(id)\n",
    "        #check if same vehicle is moving\n",
    "        if (tracker.f[id] == 1 and s != 0): \n",
    "            #call the capture method of tracker.\n",
    "            tracker.capture(roi, x, y, h, w, s, id)\n",
    "    #DRAW LINES\n",
    "    #draw a line where timer ends\n",
    "    cv2.line(roi, (0, 410), (960, 410), (0, 0, 255), 2) \n",
    "    cv2.line(roi, (0, 430), (960, 430), (0, 0, 255), 2) \n",
    "    #draw a line where timer starts \n",
    "    cv2.line (roi, (0, 235), (960, 235), (0, 0, 255), 2) \n",
    "    cv2.line(roi, (0, 255), (960, 255), (0, 0, 255), 2)\n",
    "\n",
    "    #DISPLAY\n",
    "    #cv2.imshow(\"Mask\", mask2) \n",
    "    #cv2.imshow(\"Erode\", e_img)\n",
    "    cv2.imshow(\"ROI\", roi)\n",
    "    key = cv2.waitKey(w-10)\n",
    "    if key==27:\n",
    "        tracker.end()\n",
    "        end=1\n",
    "        break\n",
    "if(end!=1):\n",
    "    tracker.end()\n",
    "cap.release()\n",
    "cv2.destroyAllwindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5aea4e",
   "metadata": {},
   "source": [
    "## Drafting detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4828b3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Imports:\n",
    "from keras.preprocessing.image import img_to_array,load_img \n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from keras.layers import Conv30, ConvLSTM20, Conv30Transpose\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping \n",
    "import imutils\n",
    "#Initialize directory path variable and describe a function to process and store video frames:\n",
    "store_image=[]\n",
    "train_path='./traini'\n",
    "fps=5\n",
    "train_videos=os.listdir(train_path)\n",
    "#convert the image into array\n",
    "def store inarray(image_path):\n",
    "    image=load_img(image_path) \n",
    "    image=img_to_array(image)\n",
    "    image=cv2.resize(image, (227,227), interpolation = cv2.INTER_AREA)\n",
    "    gray=0.2989*image[:,:,0] +0.5870*image[:,:,1] +0.1140*image[:,:,2]\n",
    "    store_image.append(gray)\n",
    "    \n",
    "def video_to_frames (input_loc, output_loc): \n",
    "    \"\"\"Function to extract frames from input video file\n",
    "    and save them as separate frames in an output directory. \n",
    "    Args:\n",
    "        input_loc: Input video file. \n",
    "        output_loc: Output directory to save the frames.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.mkdir(output_loc)\n",
    "    except OSError:\n",
    "        pass\n",
    "    #Log the time\n",
    "    time_start = time.time()\n",
    "    #Start capturing the feed\n",
    "    cap = cv2.VideoCapture(input_loc)\n",
    "    #Find the number of frames\n",
    "    video length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) - 1\n",
    "    print (\"Number of frames: \", video_length)\n",
    "    count = 10\n",
    "    print (\"Converting video..\\n\") \n",
    "    #Start converting the video\n",
    "    while cap.isOpened():\n",
    "        #Extract the frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        # Write the results back to output location.\n",
    "        cv2.imwrite(output_loc + \"/%#05d.jpg\" % (count+1), frame)\n",
    "        count=count + 1\n",
    "        # If there are no more frames Left \n",
    "        if (count > (video_length-1)):\n",
    "            # Log the time again\n",
    "            time_end = time.time()\n",
    "            # Release the feed \n",
    "            cap.release()\n",
    "            # Print stats\n",
    "            print (\"Done extracting frames. \\nd frames extracted\" % count) \n",
    "            print (\"It took %d seconds forconversion.\" % (time_end-time_start))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d01a2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import cv2\n",
    "# this calls the functions that are described above and stores the images in the respected video folder\n",
    "baseOut_loc= \"C:/Users/Pavani/Desktop/MiniProject2/videoSur/train1/frames/\"\n",
    "i=0\n",
    "for video in train_videos:\n",
    "    input_loc= \"C:/Users/Pavani/Desktop/MiniProject2/videoSur/train1/\"+video \n",
    "    imagespath-baseOut_loc+'/video' +str(i)\n",
    "    i +=1\n",
    "    os.makedirs(imagespath)\n",
    "    output_loc= imagespath\n",
    "    video_to_frames (input_loc, output_loc)\n",
    "    images = os.listdir(output_loc)\n",
    "    for image in images:\n",
    "        image_path = output_loc+'/'+image \n",
    "        store_inarray(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b212fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts the images into numpy arrays\n",
    "store_image=np.array(store_image)\n",
    "#a,b,c=store_image.shape\n",
    "#store_image.resize(b,c,a)\n",
    "store_image=(store_image-store_image.mean())/(store_image.std())\n",
    "store_image=np.clip(store_image,0,1)\n",
    "np.save('training.npy', store_image)\n",
    "\n",
    "#This is the our training model and with layers\n",
    "stae_model=Sequential()\n",
    "\n",
    "stae_model.add(Conv3D (filters=128, kernel_size=(11,11,1), strides (4,4,1),padding='valid', input_shape=(227,227,10,1), activation:'tanh')) \n",
    "stae_model.add(Conv3D (filters=64, kernel_size=(5,5,1), strides (2,2,1), padding= 'valid', activation= 'tanh'))\n",
    "stae_model.add(ConvLSTM2D(filters=64, kernel_size=(3,3), strides 1,padding='same', dropout=0.4, recurrent_dropout=8.3, return_sequences=True))\n",
    "stae_model.add(ConvLSTM2D (filters=32, kernel_size=(3,3), strides 1, padding='same', dropout 0.3, return_sequences=True))\n",
    "stae_model.add(ConvLSTM2D(filters=64, kernel_size=(3,3), strides 1, return_sequences=True, padding='same, dropout=0.5))\n",
    "stae_model.add(Conv3DTranspose(filters 128, kernel_size=(5,5,1), strides (2,2,1),padding='valid', activations:'tanh'))\n",
    "stae_model.add(Conv3DTranspose(filters=1, kernel_size=(11,11,1), strides (4,4,1), padding='valid', activation: 'tanh'))\n",
    "stae_model.compile(optimizer:' adam', loss='mean squared error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d0c471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we train our models with image orrays.\n",
    "training_data=np.load('training.npy\")\n",
    "frames=training_data.shape[2]\n",
    "frames=frames-frames%10\n",
    "\n",
    "#training data training data[:,:frames]\n",
    "training_data=training data[:frames]\n",
    "training_data=training_data.reshape(-1,227,227,10)\n",
    "training_data=np.expand_dims(training data, axis=4)\n",
    "target_data=training_data.copy()\n",
    "\n",
    "epochs=2\n",
    "batch size=1\n",
    "\n",
    "callback_save = ModelCheckpoint (\"saved_model.h5\", monitor=\"mean_squared_error\", save_best_only=True)\n",
    "callback_early_stopping=EarlyStopping(monitors'val_loss', patience=3)\n",
    "stae_model.fit(training_data, target_data, batch_size=batch_size, epochs=epochs, callbacks = [callback_save, callback_early_stopping])\n",
    "stae_model.save(\"saved modelling.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cf4659",
   "metadata": {},
   "source": [
    "## Finding Drifing of vehicle(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c587b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import argparse\n",
    "from PIL import Image\n",
    "import imutils\n",
    "# this is the function to calculate the difference between original image and predicted image\n",
    "def mean squared_loss (x1,x2):\n",
    "    difference=x1-x2\n",
    "    a,b,c,d,e=difference.shape \n",
    "    n_samples=a*b*c*d*e\n",
    "    sq_difference=difference**2\n",
    "    Sum=sq_difference.sum()\n",
    "    distance=np.sqrt(Sum)\n",
    "    mean_distance=distance/n_samples\n",
    "    return mean_distance\n",
    "\n",
    "model=load_model(\"saved_modelling.h5\")\n",
    "cap = cv2.VideoCapture(\"C:/Users/Pavani/Desktop/VehicleSpeeddetection/Project Video.mp4\")\n",
    "#cop = cv2.VideoCapture(0)\n",
    "#cap= cv2. VideoCapture(\"C:/Users/Pavani/Desktop/MiniProject2/videoSur/troin1/Suzuki Swift Sport Drift P.mp4\")\n",
    "print(cap.isOpened())\n",
    "while cap.isOpened():\n",
    "    imagedump=[]\n",
    "    ret, frame=cap.read()\n",
    "    for i in range(10):\n",
    "        ret, frame=cap.read()\n",
    "        if frame is not None:\n",
    "            image imutils.resize(frame, width=700,height=600)\n",
    "\n",
    "            frame=cv2.resize(frame, (227,227), interpolation = cv2.INTER_AREA) \n",
    "            gray=0.2989*frame[:,:,0]+0.5870*frame[:,:,1]+0.1140*frame[:,:,2]\n",
    "            gray=(gray-gray mean())/gray.std()\n",
    "            gray=np.clip(gray,0,1)\n",
    "            imagedump.append(gray)\n",
    "            \n",
    "    imagedump np.array(imagedump)\n",
    "    \n",
    "    imagedump.resize(227,227,10)\n",
    "    imagedump=np.expand_dims(imagedump, axis=0)\n",
    "    imagedump=np.expand_dims(imagedump, axis=4)\n",
    "    \n",
    "    output=model.predict(imagedump)\n",
    "    loss=mean_squared_loss(imagedump, output)\n",
    "    #if frame.any()==None:\n",
    "        # print(\"none\")\n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "        break\n",
    "    #if Loss>0.00068:\n",
    "    print(loss)\n",
    "    if loss 0.00065:\n",
    "        print('Abnormal Event Detected')\n",
    "        cv2.putText(image, \"Abnormal Event\", (100, 80), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,0,255),4)\n",
    "    else:\n",
    "        cv2.putText(image, \"Not Abnormal Event\", (100,80), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,255, 255),4) \n",
    "        print(\"no abnormal activities are detected\")\n",
    "    cv2.imshow(\"video\", image)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573bb754",
   "metadata": {},
   "source": [
    "## Number plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa6a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary Libraries\n",
    "import cv2\n",
    "import imutils\n",
    "import pytesseract\n",
    "#add pytessaract path\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files (x86)/Tesseract-OCR/tesseract.exe\"\n",
    "#Loop over images that crossed speed limit\n",
    "for i in range(1,6): #specify the Location\n",
    "    location = \"C:/Users/Pavani/Desktop/VehicleSpeeddetection/exceeded1/ing\"+str(i)+\".jpg\"\n",
    "    print(location)\n",
    "    #read the image\n",
    "    image = cv2.imread(location)\n",
    "    #resize the image\n",
    "    image =imutils.resize(image, width =500)\n",
    "    #show the image\n",
    "    cv2.imshow(\"original image\", image) \n",
    "    #press a to get next image\n",
    "    cv2.waitKey(0)\n",
    "    #convert colored image to gray image \n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    #show the gray image\n",
    "    cv2.imshow(\"Gray Scale Image\", gray)\n",
    "    cv2.waitKey(0)\n",
    "    #Make the gray image into more smoother by applying filters \n",
    "    gray = cv2.bilateral Filter (gray,11,17,17) \n",
    "    #show the smoother image \n",
    "    cv2.imshow(\"smoother Image\", gray)\n",
    "    cv2.waitKey(0)\n",
    "    #draw canny edges\n",
    "    edged = cv2.Canny (gray, 170, 200)\n",
    "    #display the canny edged image \n",
    "    cv2.imshow(\"Canny Edge\", edged)\n",
    "    cv2.waitKey(0)\n",
    "    #find contours among images\n",
    "    cnts = cv2.findContours (edged.copy(),cv2.RETR_LIST, cv2.CHAIN APPROX SIMPLE)[1]\n",
    "    #copy the image\n",
    "    imagel image.copy()\n",
    "    #then draw the contours\n",
    "    cv2.drawContours (image1, cnts, -1, (0,255,0), 3)\n",
    "    #then show the image after contouring\n",
    "    cv2.imshow(\"Canny After Contouring\", image1)\n",
    "    cv2.waitKey(0)\n",
    "    #sort the contours based on countour area \n",
    "    cnts=sorted (cnts, key = cv2.contourArea, reverse=True) [:30]\n",
    "    NumberPlateCount = None\n",
    "    image2 image.copy()\n",
    "    cv2.drawContours (image2, cnts, -1, (0,255,0),3)\n",
    "    #display the top 30 contours\n",
    "    cv2.imshow(\"Top 30 Contours\", image2)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    count = 0\n",
    "    name = 1\n",
    "    for i in cnts:\n",
    "        perimeter = cv2.arcLength (i, True)\n",
    "        approx = cv2.approxPolyDP (1,0.02 perimeter, True)\n",
    "        #display the contour which has approximate value 4 and then store the image\n",
    "        if(len(approx)==4):\n",
    "            NumberPlateCount = approx\n",
    "            x,y,w,h = cv2.boundingRect(i) \n",
    "            crp_img = image[y:y+h, x:x+w]\n",
    "            \n",
    "            cv2.imwrite(str(name)+'.png', crp_img)\n",
    "            name +1\n",
    "            break\n",
    "        #drawcontours and show the final image of number plate\n",
    "    cv2.drawContours (image, [NumberPlateCount], -1, (0,255,0),3) \n",
    "    cv2.imshow(\"Final Image\", image) \n",
    "    crop_img_loc= '1.png' \n",
    "    cv2.imshow(\"Cropped Image\",cv2.imread(crop_img_loc)) \n",
    "    text = pytesseract.image_to_string(crop_img_loc, lang = 'eng', config='--psm 6')\n",
    "    cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f643b2",
   "metadata": {},
   "source": [
    "## Alert message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49663df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import smtlib for dealing with mail operations\n",
    "import smtplib\n",
    "    #import pandas library to read csv file of Licence data\n",
    "import pandas as pd\n",
    "    #Read Licence data of people who have done rash driving\n",
    "data = pd.read_csv(\"C:/Users/Pavani/Desktop/Vehicle Speeddetection/information.csv\")\n",
    "#extract the names from data file\n",
    "names data['Name']\n",
    "#extract mails from data file\n",
    "mails = data['Email']\n",
    "#Make connection with server\n",
    "server = smtplib.SMTP('smtp.gmail.com',587)\n",
    "#start the server\n",
    "server.starttls()\n",
    "#Log into server using credentials\n",
    "server.login(\"majorproject127@gmail.com\", 'project@89')\n",
    "#Loop through the names and mails\n",
    "for i in range(len(names)):\n",
    "    #customize the message by writing particular names\n",
    "    msg = \"Dear \"+names[i]+\"\\n\\n You are crossing traffic rules and that may cause accidents.Drive Safe and ensure the safety of others\"\n",
    "    #add subject\n",
    "    SUBJECT: 'Warning Regarding Violation of Traffic Rules\"\n",
    "    #format the messages\n",
    "    message= 'Subject: [\\n\\n().format(SUBJECT, msg)\n",
    "    #send mail\n",
    "    server.sendmail(\"majorproject127@gmail.com\",mails[i],message) \n",
    "    #in order to confirm just print Mail sent, if mail is not sent this Line wont execute because\n",
    "    #code execution stop before itself.\n",
    "    print(\"Mail Sent\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
